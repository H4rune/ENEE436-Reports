{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "CNN Modifications",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxPuFdZK5uy3"
      },
      "source": [
        "\n",
        "\n",
        "# **Building a Convolutional Neural Network with TensorFlow.**\n",
        " \n",
        " \n",
        "\n",
        "> Foundations of Machine Learning (ENEE436/ENTS669D) - Spring 2022\n",
        "\n",
        "> Prof. Behtash Babadi, ECE, UMD\n",
        "\n",
        "Author: Christos Mavridis (<mavridis@umd.edu>)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNv9Ds9k5uy9"
      },
      "source": [
        "## MNIST Dataset Overview\n",
        "\n",
        "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. \n",
        "\n",
        "<a title=\"By Josef Steppan [CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0)], from Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:MnistExamples.png\"><img width=\"512\" alt=\"MnistExamples\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\"/></a>\n",
        "\n",
        "More info: http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMhCEA5e_e0W"
      },
      "source": [
        "## Load MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkunKnNr_fzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad6dac9-c50e-4ba3-c558-f77e5bba5774"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "import distutils\n",
        "import pandas as pd\n",
        "if distutils.version.LooseVersion(tf.__version__) <= '2.0':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train0 = y_train\n",
        "y_test0= y_test\n",
        "\n",
        "# add empty color dimension\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "\n",
        "print(f'Input image dimension: {x_train.shape[1:]}')\n",
        "\n",
        "#Run this cell before any other"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Input image dimension: (28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_X069QhuXBa"
      },
      "source": [
        "# Why CNN?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKETDYiMuZ-N"
      },
      "source": [
        "### CNN Overview\n",
        "\n",
        "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n",
        "\n",
        "### Convolutions\n",
        "\n",
        "- Reduce number of weights (weight sharing, Toeplitz matrix)\n",
        "- Learn linear time-invariant systems (convolutional filters) which were typically used ad-hoc as pre-processing steps and required domain knowledge (e.g. Laplacian filters = edge detectors in images)\n",
        "- Output size (1D): n-m+1 (n:input size, m:filter size)\n",
        "\n",
        "<img width=\"512\" alt=\"MnistExamples\" src=\"https://miro.medium.com/max/2880/0*QS1ArBEUJjjySXhE.png\"/>\n",
        "\n",
        "### Pooling\n",
        "\n",
        "- Dimensionality reduction\n",
        "- Build hierarchy \n",
        "\n",
        "<img width=\"512\" alt=\"MnistExamples\" src=\"https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\"/>\n",
        "\n",
        "\n",
        "### Activation functions\n",
        "\n",
        "<img width=\"512\" alt=\"MnistExamples\" src=\"https://miro.medium.com/max/2800/0*44z992IXd9rqyIWk.png\"/>\n",
        "\n",
        "### Softmax --> Gibbs (Boltzmann) distr. --> Probabilities\n",
        "\n",
        "<img width=\"512\" alt=\"MnistExamples\" src=\"https://www.andreaperlato.com/img/softmaxfunction.png\"/>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Automatic feature extraction\n",
        "\n",
        "<img width=\"512\" alt=\"MnistExamples\" src=\"https://miro.medium.com/max/616/1*Uhr-4VDJD0-gnteUNFzZTw.jpeg\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuG2yEiDvZH3"
      },
      "source": [
        "## Building a CNN: Example of LeNet5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZPeNEX0AK_5"
      },
      "source": [
        "\n",
        "![CNN](https://cdn-images-1.medium.com/max/800/0*V1vb9SDnsU1eZQUy.jpg)\n",
        "\n",
        "#### MNIST Input\n",
        "    32x32x1 pixels image\n",
        "\n",
        "#### Architecture\n",
        "* **Convolutional #1** \n",
        "    * Filters: 6\n",
        "    * Filter size: 5x5 \n",
        "    * --> Output 28x28x6\n",
        "    * Activation: `relu`\n",
        "\n",
        "* **Pooling #1** \n",
        "    * The output shape should be 14x14x6.\n",
        "\n",
        "* **Convolutional #2** \n",
        "\n",
        "* **Pooling #2** \n",
        "\n",
        "* **Fully Connected #1** outputs 120\n",
        "    \n",
        "* **Fully Connected #2** outputs 84\n",
        "    \n",
        "* **Fully Connected #3** output 10 (# classes)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6MFkQknIfAY"
      },
      "source": [
        "## Custom CNN Design\n",
        "\n",
        "#### MNIST Input\n",
        "    28x28x1 pixels image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6sSEiv1ALKK",
        "outputId": "33466c34-1b9b-4d81-d69a-c724d683ba7d"
      },
      "source": [
        "def myCNN():\n",
        "  \n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # First Layer\n",
        "  model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu',input_shape=x_train.shape[1:]))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  # Second Layer\n",
        "  model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  # Fully-connected NNs\n",
        "  model.add(tf.keras.layers.Dense(units=120, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation = 'softmax'))\n",
        "  \n",
        "  return model\n",
        "\n",
        "print('Model Structure & Parameters:')\n",
        "model = myCNN()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Structure & Parameters:\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 24, 24, 6)         156       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 12, 12, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 16)        880       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,170\n",
            "Trainable params: 60,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O5S7lao_4nD"
      },
      "source": [
        "# Optimization Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLehbYPWz6vv"
      },
      "source": [
        "- Stochastic Gradient Descent\n",
        "\n",
        "<img width=\"512\" alt=\"MnistExamples\" src=\"https://miro.medium.com/max/425/1*m1KQOLl-qB0mgRq_IWivnQ.png\"/>\n",
        "\n",
        "- Adaptive momentum method (Adam)\n",
        "\n",
        "<img width=\"256\" alt=\"MnistExamples\" src=\"https://miro.medium.com/max/380/1*Ti-cvetTBXnTsM6rHUhmlg.png\"/>\n",
        "\n",
        "- Race to global minima\n",
        "\n",
        "<img width=\"512\" alt=\"MnistExamples\" src=\"https://miro.medium.com/max/700/1*m7-otgfbxiAvSipInHliXw.gif\"/>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsG3xc7F5uy_"
      },
      "source": [
        "# Training Parameters\n",
        "EPOCHS = 2 #10\n",
        "BATCH_SIZE = 256 #128 \n",
        "\n",
        "# Loss Function\n",
        "loss_fn = tf.keras.losses.categorical_crossentropy\n",
        "# Why don't you try these as well?\n",
        "# loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "# loss_fn = tf.keras.losses.Hinge()\n",
        "\n",
        "# Optimization Method\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False)\n",
        "# Why don't you try these as well?\n",
        "# tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
        "# tf.keras.optimizers.Adagrad(learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07)\n",
        "\n",
        "model.compile(loss=loss_fn, optimizer=optimizer, metrics=['accuracy'])\n",
        "if loss_fn == tf.keras.losses.categorical_crossentropy:\n",
        "    y_train = tf.keras.utils.to_categorical(y_train0)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iaf8LThZNkI5"
      },
      "source": [
        "# Training Loop and Testing Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlpuikf8NkSX",
        "outputId": "6078cba5-3e96-47b1-c839-5ffbad7bd5a1"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose = 1) # Verbose controls the output frequency during training\n",
        "\n",
        "\n",
        "\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Train accuracy:', train_acc)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "235/235 [==============================] - 28s 115ms/step - loss: 0.4190 - accuracy: 0.8814\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 0.1070 - accuracy: 0.9678\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0779 - accuracy: 0.9763\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0733 - accuracy: 0.9774\n",
            "Train accuracy: 0.9762833118438721\n",
            "Test accuracy: 0.977400004863739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#My  new code to generate data and such\n",
        "\n",
        "#Just alter the number of features in each conv layer\n",
        "#This code will cycle through number of CNN features and put data into a csv\n",
        "\n",
        "convfeats1 = [1,3,5,6,7,9,11]\n",
        "convfeats2 = [12,15,16,17,19,21,25]\n",
        "\n",
        "df = pd.DataFrame(columns = [\"Conv Features Layer 1\",\"Conv Features Layer 2\",\n",
        "                             \"Train Loss\", \"Train Accuracy\",\"Test Loss\",\n",
        "                             \"Test Accuracy\"])\n",
        "\n",
        "for feat1 in convfeats1:\n",
        "\n",
        "  for feat2 in convfeats2:\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # First Layer\n",
        "    model.add(tf.keras.layers.Conv2D(filters=feat1, kernel_size=(5, 5), activation='relu',input_shape=x_train.shape[1:]))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "    # Second Layer\n",
        "    model.add(tf.keras.layers.Conv2D(filters=feat2, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    # Fully-connected NNs\n",
        "    model.add(tf.keras.layers.Dense(units=120, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    #loss func\n",
        "    loss_fn = tf.keras.losses.categorical_crossentropy\n",
        "\n",
        "    #optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False)\n",
        "\n",
        "    model.compile(loss=loss_fn, optimizer=optimizer, metrics=['accuracy'])\n",
        "    if loss_fn == tf.keras.losses.categorical_crossentropy:\n",
        "      y_train = tf.keras.utils.to_categorical(y_train0)\n",
        "      y_test = tf.keras.utils.to_categorical(y_test0)\n",
        "    \n",
        "    model.fit(x_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose = 1) # Verbose controls the output frequency during training\n",
        "\n",
        "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "    newdf = pd.DataFrame([[feat1,feat2,train_loss,train_acc,test_loss,test_acc]]\n",
        "                         ,columns = df.columns)\n",
        "    \n",
        "    df = pd.concat([df,newdf],axis = 0, ignore_index= True)\n",
        "\n",
        "df.to_csv('convdata1.csv')\n"
      ],
      "metadata": {
        "id": "Tt4_hYeCM7EP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3e0621-48e9-4506-9d4f-70f858f7d9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "235/235 [==============================] - 16s 68ms/step - loss: 0.5431 - accuracy: 0.8512\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.1489 - accuracy: 0.9546\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1219 - accuracy: 0.9620\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1149 - accuracy: 0.9657\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 18s 74ms/step - loss: 0.5621 - accuracy: 0.8504\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 17s 72ms/step - loss: 0.1381 - accuracy: 0.9568\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1160 - accuracy: 0.9639\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1107 - accuracy: 0.9663\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 17s 68ms/step - loss: 0.4799 - accuracy: 0.8682\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 16s 69ms/step - loss: 0.1451 - accuracy: 0.9549\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1182 - accuracy: 0.9640\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1091 - accuracy: 0.9664\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 17s 69ms/step - loss: 0.5662 - accuracy: 0.8383\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 16s 69ms/step - loss: 0.1627 - accuracy: 0.9499\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1268 - accuracy: 0.9616\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1194 - accuracy: 0.9617\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.5837 - accuracy: 0.8284\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.1837 - accuracy: 0.9428\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1296 - accuracy: 0.9607\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1211 - accuracy: 0.9616\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 17s 70ms/step - loss: 0.5238 - accuracy: 0.8564\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 17s 71ms/step - loss: 0.1569 - accuracy: 0.9525\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1218 - accuracy: 0.9621\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.1104 - accuracy: 0.9646\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 17s 71ms/step - loss: 0.4702 - accuracy: 0.8761\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 17s 72ms/step - loss: 0.1217 - accuracy: 0.9620\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0923 - accuracy: 0.9717\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.0885 - accuracy: 0.9730\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 19s 77ms/step - loss: 0.5070 - accuracy: 0.8529\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 18s 77ms/step - loss: 0.1484 - accuracy: 0.9562\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1179 - accuracy: 0.9639\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1118 - accuracy: 0.9657\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 19s 80ms/step - loss: 0.4949 - accuracy: 0.8610\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 19s 79ms/step - loss: 0.1270 - accuracy: 0.9616\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1022 - accuracy: 0.9686\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0955 - accuracy: 0.9725\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 19s 78ms/step - loss: 0.4931 - accuracy: 0.8545\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 18s 78ms/step - loss: 0.1390 - accuracy: 0.9585\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1065 - accuracy: 0.9668\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0955 - accuracy: 0.9671\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 19s 78ms/step - loss: 0.4799 - accuracy: 0.8616\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 18s 78ms/step - loss: 0.1293 - accuracy: 0.9613\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0914 - accuracy: 0.9720\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0845 - accuracy: 0.9746\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 20s 82ms/step - loss: 0.4884 - accuracy: 0.8559\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 19s 81ms/step - loss: 0.1193 - accuracy: 0.9638\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0856 - accuracy: 0.9748\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0780 - accuracy: 0.9760\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 20s 81ms/step - loss: 0.4458 - accuracy: 0.8713\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 19s 81ms/step - loss: 0.1290 - accuracy: 0.9604\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1055 - accuracy: 0.9672\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0965 - accuracy: 0.9707\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 20s 81ms/step - loss: 0.4713 - accuracy: 0.8655\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 19s 83ms/step - loss: 0.1155 - accuracy: 0.9658\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0826 - accuracy: 0.9750\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0801 - accuracy: 0.9751\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 20s 83ms/step - loss: 0.4707 - accuracy: 0.8702\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 19s 83ms/step - loss: 0.1318 - accuracy: 0.9604\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1074 - accuracy: 0.9678\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0986 - accuracy: 0.9686\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 86ms/step - loss: 0.4477 - accuracy: 0.8665\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.1029 - accuracy: 0.9688\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0769 - accuracy: 0.9763\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0649 - accuracy: 0.9795\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.4389 - accuracy: 0.8768\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 20s 84ms/step - loss: 0.1115 - accuracy: 0.9662\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0871 - accuracy: 0.9735\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0809 - accuracy: 0.9754\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 85ms/step - loss: 0.4674 - accuracy: 0.8708\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 0.1007 - accuracy: 0.9699\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0862 - accuracy: 0.9738\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0800 - accuracy: 0.9741\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 87ms/step - loss: 0.4005 - accuracy: 0.8870\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 20s 87ms/step - loss: 0.0996 - accuracy: 0.9693\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0749 - accuracy: 0.9770\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0712 - accuracy: 0.9760\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 88ms/step - loss: 0.3822 - accuracy: 0.8938\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 87ms/step - loss: 0.0956 - accuracy: 0.9709\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0792 - accuracy: 0.9753\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0772 - accuracy: 0.9755\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 90ms/step - loss: 0.4110 - accuracy: 0.8820\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 89ms/step - loss: 0.1076 - accuracy: 0.9669\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0887 - accuracy: 0.9723\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0808 - accuracy: 0.9738\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.4765 - accuracy: 0.8673\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.1072 - accuracy: 0.9681\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0872 - accuracy: 0.9738\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0777 - accuracy: 0.9762\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 88ms/step - loss: 0.4591 - accuracy: 0.8719\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 89ms/step - loss: 0.1076 - accuracy: 0.9674\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0778 - accuracy: 0.9767\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0743 - accuracy: 0.9769\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 86ms/step - loss: 0.4432 - accuracy: 0.8759\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 0.1096 - accuracy: 0.9664\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0867 - accuracy: 0.9734\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0752 - accuracy: 0.9766\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 87ms/step - loss: 0.4802 - accuracy: 0.8700\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 88ms/step - loss: 0.1078 - accuracy: 0.9677\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0891 - accuracy: 0.9723\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0789 - accuracy: 0.9750\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 89ms/step - loss: 0.4131 - accuracy: 0.8880\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 89ms/step - loss: 0.0916 - accuracy: 0.9718\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0688 - accuracy: 0.9785\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0644 - accuracy: 0.9794\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 88ms/step - loss: 0.4280 - accuracy: 0.8798\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 89ms/step - loss: 0.1000 - accuracy: 0.9694\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0719 - accuracy: 0.9780\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0651 - accuracy: 0.9782\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 90ms/step - loss: 0.4374 - accuracy: 0.8760\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 91ms/step - loss: 0.1063 - accuracy: 0.9689\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0833 - accuracy: 0.9753\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0733 - accuracy: 0.9764\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 89ms/step - loss: 0.4618 - accuracy: 0.8642\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 91ms/step - loss: 0.1088 - accuracy: 0.9669\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0845 - accuracy: 0.9745\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0774 - accuracy: 0.9757\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 92ms/step - loss: 0.4793 - accuracy: 0.8532\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 22s 92ms/step - loss: 0.1307 - accuracy: 0.9611\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1037 - accuracy: 0.9689\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1006 - accuracy: 0.9671\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 90ms/step - loss: 0.4355 - accuracy: 0.8784\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 90ms/step - loss: 0.1036 - accuracy: 0.9689\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0750 - accuracy: 0.9776\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0694 - accuracy: 0.9779\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 92ms/step - loss: 0.4560 - accuracy: 0.8708\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 22s 92ms/step - loss: 0.0981 - accuracy: 0.9698\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0746 - accuracy: 0.9772\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0716 - accuracy: 0.9786\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 93ms/step - loss: 0.4008 - accuracy: 0.8880\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 22s 93ms/step - loss: 0.0928 - accuracy: 0.9716\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0705 - accuracy: 0.9782\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0635 - accuracy: 0.9797\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 23s 94ms/step - loss: 0.4445 - accuracy: 0.8732\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 22s 94ms/step - loss: 0.1120 - accuracy: 0.9671\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0833 - accuracy: 0.9746\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0722 - accuracy: 0.9760\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 23s 95ms/step - loss: 0.4096 - accuracy: 0.8808\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 22s 95ms/step - loss: 0.1012 - accuracy: 0.9689\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0748 - accuracy: 0.9786\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0686 - accuracy: 0.9781\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 85ms/step - loss: 0.4313 - accuracy: 0.8769\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 20s 85ms/step - loss: 0.1035 - accuracy: 0.9684\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0816 - accuracy: 0.9746\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0692 - accuracy: 0.9781\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 89ms/step - loss: 0.4274 - accuracy: 0.8819\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 89ms/step - loss: 0.1174 - accuracy: 0.9656\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0882 - accuracy: 0.9744\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0824 - accuracy: 0.9746\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 86ms/step - loss: 0.4480 - accuracy: 0.8712\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 20s 86ms/step - loss: 0.0966 - accuracy: 0.9710\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0747 - accuracy: 0.9772\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0705 - accuracy: 0.9784\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 21s 88ms/step - loss: 0.4178 - accuracy: 0.8816\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 88ms/step - loss: 0.0950 - accuracy: 0.9711\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0681 - accuracy: 0.9795\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0631 - accuracy: 0.9801\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 90ms/step - loss: 0.3905 - accuracy: 0.8912\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 90ms/step - loss: 0.0920 - accuracy: 0.9721\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0762 - accuracy: 0.9766\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0703 - accuracy: 0.9773\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 93ms/step - loss: 0.3653 - accuracy: 0.8964\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 22s 93ms/step - loss: 0.0937 - accuracy: 0.9718\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0696 - accuracy: 0.9790\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0618 - accuracy: 0.9801\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 92ms/step - loss: 0.3785 - accuracy: 0.8917\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 22s 93ms/step - loss: 0.0926 - accuracy: 0.9723\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0719 - accuracy: 0.9785\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0648 - accuracy: 0.9797\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 91ms/step - loss: 0.4272 - accuracy: 0.8757\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 21s 91ms/step - loss: 0.0992 - accuracy: 0.9698\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0726 - accuracy: 0.9780\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0644 - accuracy: 0.9779\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 23s 95ms/step - loss: 0.4263 - accuracy: 0.8779\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 22s 95ms/step - loss: 0.0886 - accuracy: 0.9731\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0653 - accuracy: 0.9804\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0586 - accuracy: 0.9804\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 22s 93ms/step - loss: 0.4107 - accuracy: 0.8892\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 22s 94ms/step - loss: 0.0914 - accuracy: 0.9728\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0644 - accuracy: 0.9807\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0571 - accuracy: 0.9822\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 23s 96ms/step - loss: 0.4175 - accuracy: 0.8816\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 23s 97ms/step - loss: 0.0922 - accuracy: 0.9725\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0656 - accuracy: 0.9807\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0611 - accuracy: 0.9805\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.4142 - accuracy: 0.8839\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.0903 - accuracy: 0.9727\n",
            "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0661 - accuracy: 0.9800\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0598 - accuracy: 0.9806\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 24s 99ms/step - loss: 0.4212 - accuracy: 0.8760\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 23s 98ms/step - loss: 0.1116 - accuracy: 0.9667\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0799 - accuracy: 0.9769\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0744 - accuracy: 0.9778\n",
            "Epoch 1/2\n",
            "235/235 [==============================] - 24s 100ms/step - loss: 0.3788 - accuracy: 0.8899\n",
            "Epoch 2/2\n",
            "235/235 [==============================] - 23s 99ms/step - loss: 0.0830 - accuracy: 0.9743\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0625 - accuracy: 0.9812\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0575 - accuracy: 0.9803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#My  new code to generate data and such\n",
        "\n",
        "#Just alter the optimizer and parameters\n",
        "#This code will alter the optimizer and learning rate and will create a csv file\n",
        "#With all the relevant data\n",
        "\n",
        "optimizer = range(1,9)\n",
        "learningrate = np.logspace(-3,-.5,6)\n",
        "\n",
        "dfhist = pd.DataFrame()\n",
        "dffinal = pd.DataFrame(index = [\"TrainLoss\",\"TrainAcc\",\"TestLoss\",\"TestAcc\"])\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# First Layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu',input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "# Second Layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "  \n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Fully-connected NNs\n",
        "model.add(tf.keras.layers.Dense(units=120, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "#loss func\n",
        "loss_fn = tf.keras.losses.categorical_crossentropy\n",
        "\n",
        "weights = model.get_weights()\n",
        "\n",
        "\n",
        "for num in optimizer:\n",
        "\n",
        "  for rate in learningrate:\n",
        "\n",
        "    model.set_weights(weights)\n",
        "\n",
        "    #optimizer depends on type\n",
        "    if(num == 1):\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate= rate,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False)\n",
        "    elif(num == 2):\n",
        "      optimizer =  tf.keras.optimizers.SGD(learning_rate= rate, momentum=0.0, nesterov=False)\n",
        "    elif(num == 3):\n",
        "      optimizer =  tf.keras.optimizers.Adagrad(learning_rate= rate,initial_accumulator_value=0.1,epsilon=1e-07)\n",
        "    elif(num == 4):\n",
        "      optimizer =  tf.keras.optimizers.RMSprop(learning_rate = rate)\n",
        "    elif(num == 5):\n",
        "      optimizer =  tf.keras.optimizers.Adadelta(learning_rate = rate)\n",
        "    elif(num == 6):\n",
        "      optimizer =  tf.keras.optimizers.Adamax(learning_rate = rate)\n",
        "    elif(num == 7):\n",
        "      optimizer =  tf.keras.optimizers.Nadam(learning_rate = rate)\n",
        "    else:\n",
        "      optimizer =  tf.keras.optimizers.Ftrl(learning_rate = rate)\n",
        "\n",
        "    model.compile(loss=loss_fn, optimizer=optimizer, metrics=['accuracy'])\n",
        "    if loss_fn == tf.keras.losses.categorical_crossentropy:\n",
        "      y_train = tf.keras.utils.to_categorical(y_train0)\n",
        "      y_test = tf.keras.utils.to_categorical(y_test0)\n",
        "    \n",
        "    model.fit(x_train, y_train,\n",
        "          batch_size=512,\n",
        "          epochs=5,\n",
        "          validation_data = (x_test,y_test),\n",
        "          verbose = 1) # Verbose controls the output frequency during training\n",
        "\n",
        "    \n",
        "\n",
        "    optimizerName = \"Ftrl\"\n",
        "\n",
        "    if(num == 1):\n",
        "      optimizerName = \"Adam\"\n",
        "    elif(num == 2):\n",
        "      optimizerName = \"SGD\"\n",
        "    elif(num == 3):\n",
        "      optimizerName = \"Adagrad\"\n",
        "    elif(num == 4):\n",
        "      optimizerName = \"RMSprop\"\n",
        "    elif(num == 5):\n",
        "      optimizerName = \"Adadelta\"\n",
        "    elif(num == 6):\n",
        "      optimizerName = \"Adamax\"\n",
        "    elif(num == 7):\n",
        "      optimizerName = \"Nadam\"\n",
        "    else:\n",
        "      optimizerName = \"Ftrl\"\n",
        "\n",
        "    lst = model.history.history[\"loss\"]\n",
        "    lst.reverse()\n",
        "\n",
        "    dfhist[(optimizerName,rate,\"Training Loss\")] = lst\n",
        "    \n",
        "    lst = model.history.history[\"accuracy\"]\n",
        "    lst.reverse()\n",
        "    \n",
        "    dfhist[(optimizerName,rate,\"Training Accuracy\")] = lst\n",
        "\n",
        "    lst = model.history.history[\"val_loss\"]\n",
        "    lst.reverse()\n",
        "\n",
        "    dfhist[(optimizerName,rate,\"Validation Loss\")] = lst\n",
        "    \n",
        "    lst = model.history.history[\"val_accuracy\"]\n",
        "    lst.reverse()\n",
        "    \n",
        "    dfhist[(optimizerName,rate,\"Validation Accuracy\")] = lst\n",
        "\n",
        "    train_loss, train_acc = model.evaluate(x_train, y_train)\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "\n",
        "    dffinal[(optimizerName,rate)] = [train_loss,train_acc,test_loss,test_acc]\n",
        "    \n",
        "\n",
        "dfhist.to_csv('hist.csv')\n",
        "dffinal.to_csv('final.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFYRs7jejFXR",
        "outputId": "76767d69-953e-46a4-b0f0-0ef5e76b3e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "118/118 [==============================] - 21s 170ms/step - loss: 0.6923 - accuracy: 0.8231 - val_loss: 0.1765 - val_accuracy: 0.9463\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 167ms/step - loss: 0.1396 - accuracy: 0.9579 - val_loss: 0.0936 - val_accuracy: 0.9709\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 171ms/step - loss: 0.0974 - accuracy: 0.9703 - val_loss: 0.0734 - val_accuracy: 0.9760\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 0.0742 - accuracy: 0.9769 - val_loss: 0.0608 - val_accuracy: 0.9808\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 0.0630 - accuracy: 0.9809 - val_loss: 0.0519 - val_accuracy: 0.9831\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0558 - accuracy: 0.9828\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0519 - accuracy: 0.9831\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 21s 173ms/step - loss: 0.3905 - accuracy: 0.8871 - val_loss: 0.0965 - val_accuracy: 0.9679\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 170ms/step - loss: 0.0836 - accuracy: 0.9749 - val_loss: 0.0636 - val_accuracy: 0.9805\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 171ms/step - loss: 0.0566 - accuracy: 0.9818 - val_loss: 0.0539 - val_accuracy: 0.9832\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 173ms/step - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.0445 - val_accuracy: 0.9857\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 20s 171ms/step - loss: 0.0394 - accuracy: 0.9880 - val_loss: 0.0431 - val_accuracy: 0.9866\n",
            "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0357 - accuracy: 0.9886\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0431 - accuracy: 0.9866\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 21s 171ms/step - loss: 0.2848 - accuracy: 0.9113 - val_loss: 0.0679 - val_accuracy: 0.9783\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 0.0614 - accuracy: 0.9806 - val_loss: 0.0575 - val_accuracy: 0.9810\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 170ms/step - loss: 0.0455 - accuracy: 0.9856 - val_loss: 0.0427 - val_accuracy: 0.9850\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 168ms/step - loss: 0.0344 - accuracy: 0.9894 - val_loss: 0.0344 - val_accuracy: 0.9885\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.0393 - val_accuracy: 0.9887\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0252 - accuracy: 0.9916\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0393 - accuracy: 0.9887\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 21s 170ms/step - loss: 0.3011 - accuracy: 0.9017 - val_loss: 0.0886 - val_accuracy: 0.9709\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 170ms/step - loss: 0.0807 - accuracy: 0.9758 - val_loss: 0.0780 - val_accuracy: 0.9764\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 168ms/step - loss: 0.0726 - accuracy: 0.9783 - val_loss: 0.1009 - val_accuracy: 0.9698\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 168ms/step - loss: 0.0690 - accuracy: 0.9800 - val_loss: 0.0795 - val_accuracy: 0.9778\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 20s 166ms/step - loss: 0.0607 - accuracy: 0.9818 - val_loss: 0.0751 - val_accuracy: 0.9793\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0478 - accuracy: 0.9857\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0751 - accuracy: 0.9793\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 21s 171ms/step - loss: 2.5843 - accuracy: 0.1053 - val_loss: 2.3084 - val_accuracy: 0.1028\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.3039 - accuracy: 0.1070 - val_loss: 2.3031 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 165ms/step - loss: 2.3037 - accuracy: 0.1074 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 166ms/step - loss: 2.3034 - accuracy: 0.1077 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.3038 - accuracy: 0.1080 - val_loss: 2.3052 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 2.3049 - accuracy: 0.1124\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 2.3052 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 21s 170ms/step - loss: 46.1523 - accuracy: 0.1035 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 167ms/step - loss: 2.3050 - accuracy: 0.1089 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 168ms/step - loss: 2.3055 - accuracy: 0.1057 - val_loss: 2.3094 - val_accuracy: 0.1010\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 167ms/step - loss: 2.3063 - accuracy: 0.1063 - val_loss: 2.3096 - val_accuracy: 0.1028\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.3080 - accuracy: 0.1048 - val_loss: 2.3055 - val_accuracy: 0.1028\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 2.3067 - accuracy: 0.1044\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 2.3055 - accuracy: 0.1028\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 168ms/step - loss: 2.3032 - accuracy: 0.0938 - val_loss: 2.3011 - val_accuracy: 0.0969\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 173ms/step - loss: 2.2994 - accuracy: 0.0947 - val_loss: 2.2973 - val_accuracy: 0.0983\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 171ms/step - loss: 2.2958 - accuracy: 0.0973 - val_loss: 2.2937 - val_accuracy: 0.1014\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 170ms/step - loss: 2.2923 - accuracy: 0.1045 - val_loss: 2.2901 - val_accuracy: 0.1140\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 20s 166ms/step - loss: 2.2888 - accuracy: 0.1190 - val_loss: 2.2865 - val_accuracy: 0.1314\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 2.2870 - accuracy: 0.1286\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.2865 - accuracy: 0.1314\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 2.2993 - accuracy: 0.0957 - val_loss: 2.2931 - val_accuracy: 0.1022\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 2.2880 - accuracy: 0.1230 - val_loss: 2.2816 - val_accuracy: 0.1544\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2760 - accuracy: 0.1848 - val_loss: 2.2681 - val_accuracy: 0.2188\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2602 - accuracy: 0.2453 - val_loss: 2.2488 - val_accuracy: 0.2863\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2363 - accuracy: 0.3180 - val_loss: 2.2181 - val_accuracy: 0.3632\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 2.2196 - accuracy: 0.3601\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.2181 - accuracy: 0.3632\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 168ms/step - loss: 2.2870 - accuracy: 0.1396 - val_loss: 2.2656 - val_accuracy: 0.2203\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 2.2224 - accuracy: 0.3376 - val_loss: 2.1382 - val_accuracy: 0.4608\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 166ms/step - loss: 1.7819 - accuracy: 0.5932 - val_loss: 1.1242 - val_accuracy: 0.7390\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 164ms/step - loss: 0.7396 - accuracy: 0.8070 - val_loss: 0.5407 - val_accuracy: 0.8374\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 164ms/step - loss: 0.4645 - accuracy: 0.8649 - val_loss: 0.4508 - val_accuracy: 0.8633\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.4669 - accuracy: 0.8558\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.4508 - accuracy: 0.8633\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 72s 159ms/step - loss: 2.0786 - accuracy: 0.3618 - val_loss: 1.2962 - val_accuracy: 0.5876\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 158ms/step - loss: 0.6260 - accuracy: 0.8094 - val_loss: 0.4609 - val_accuracy: 0.8461\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 18s 156ms/step - loss: 0.2913 - accuracy: 0.9111 - val_loss: 0.2410 - val_accuracy: 0.9270\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 18s 157ms/step - loss: 0.2133 - accuracy: 0.9344 - val_loss: 0.1927 - val_accuracy: 0.9428\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 18s 156ms/step - loss: 0.1745 - accuracy: 0.9473 - val_loss: 0.1979 - val_accuracy: 0.9396\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2128 - accuracy: 0.9337\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1979 - accuracy: 0.9396\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 165ms/step - loss: 1.1703 - accuracy: 0.6383 - val_loss: 0.3001 - val_accuracy: 0.9094\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 159ms/step - loss: 0.1964 - accuracy: 0.9400 - val_loss: 0.1370 - val_accuracy: 0.9581\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 160ms/step - loss: 0.1248 - accuracy: 0.9627 - val_loss: 0.1392 - val_accuracy: 0.9555\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 159ms/step - loss: 0.0998 - accuracy: 0.9698 - val_loss: 0.0868 - val_accuracy: 0.9716\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 159ms/step - loss: 0.1014 - accuracy: 0.9687 - val_loss: 0.0827 - val_accuracy: 0.9744\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0895 - accuracy: 0.9717\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0827 - accuracy: 0.9744\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 163ms/step - loss: 1.0472 - accuracy: 0.6681 - val_loss: 0.2633 - val_accuracy: 0.9152\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 157ms/step - loss: 0.1708 - accuracy: 0.9477 - val_loss: 0.2123 - val_accuracy: 0.9293\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 158ms/step - loss: 0.0943 - accuracy: 0.9710 - val_loss: 0.1284 - val_accuracy: 0.9588\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 18s 157ms/step - loss: 0.0876 - accuracy: 0.9731 - val_loss: 0.0900 - val_accuracy: 0.9699\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 157ms/step - loss: 0.0608 - accuracy: 0.9812 - val_loss: 0.0545 - val_accuracy: 0.9823\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0531 - accuracy: 0.9834\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0545 - accuracy: 0.9823\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 19s 161ms/step - loss: 2.2993 - accuracy: 0.0954 - val_loss: 2.2933 - val_accuracy: 0.1018\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2883 - accuracy: 0.1186 - val_loss: 2.2822 - val_accuracy: 0.1468\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2769 - accuracy: 0.1759 - val_loss: 2.2696 - val_accuracy: 0.2077\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2625 - accuracy: 0.2338 - val_loss: 2.2526 - val_accuracy: 0.2739\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 161ms/step - loss: 2.2424 - accuracy: 0.3032 - val_loss: 2.2279 - val_accuracy: 0.3462\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 2.2292 - accuracy: 0.3399\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.2279 - accuracy: 0.3462\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 187ms/step - loss: 2.2872 - accuracy: 0.1353 - val_loss: 2.2663 - val_accuracy: 0.2234\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 160ms/step - loss: 2.2270 - accuracy: 0.3322 - val_loss: 2.1554 - val_accuracy: 0.4573\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 161ms/step - loss: 1.9364 - accuracy: 0.5622 - val_loss: 1.5434 - val_accuracy: 0.6918\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 160ms/step - loss: 1.0992 - accuracy: 0.7573 - val_loss: 0.7286 - val_accuracy: 0.8142\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 160ms/step - loss: 0.6131 - accuracy: 0.8372 - val_loss: 0.5013 - val_accuracy: 0.8637\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.5225 - accuracy: 0.8529\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.5013 - accuracy: 0.8637\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 162ms/step - loss: 2.0940 - accuracy: 0.3565 - val_loss: 1.2070 - val_accuracy: 0.6541\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 160ms/step - loss: 0.6595 - accuracy: 0.8065 - val_loss: 0.5765 - val_accuracy: 0.8019\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 161ms/step - loss: 0.3358 - accuracy: 0.9003 - val_loss: 0.3055 - val_accuracy: 0.9079\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 161ms/step - loss: 0.2517 - accuracy: 0.9247 - val_loss: 0.2415 - val_accuracy: 0.9291\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 160ms/step - loss: 0.2097 - accuracy: 0.9373 - val_loss: 0.1903 - val_accuracy: 0.9406\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2037 - accuracy: 0.9375\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.1903 - accuracy: 0.9406\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 163ms/step - loss: 1.1576 - accuracy: 0.6397 - val_loss: 0.7776 - val_accuracy: 0.7616\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 159ms/step - loss: 0.2181 - accuracy: 0.9359 - val_loss: 0.1610 - val_accuracy: 0.9519\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 160ms/step - loss: 0.1395 - accuracy: 0.9577 - val_loss: 0.1421 - val_accuracy: 0.9542\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 163ms/step - loss: 0.1264 - accuracy: 0.9616 - val_loss: 0.1056 - val_accuracy: 0.9674\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 0.0964 - accuracy: 0.9712 - val_loss: 0.0871 - val_accuracy: 0.9728\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1000 - accuracy: 0.9696\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0871 - accuracy: 0.9728\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 164ms/step - loss: 0.7321 - accuracy: 0.7679 - val_loss: 0.1239 - val_accuracy: 0.9622\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 165ms/step - loss: 0.1142 - accuracy: 0.9653 - val_loss: 0.0876 - val_accuracy: 0.9716\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 168ms/step - loss: 0.0811 - accuracy: 0.9743 - val_loss: 0.1254 - val_accuracy: 0.9605\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 164ms/step - loss: 0.0643 - accuracy: 0.9797 - val_loss: 0.0531 - val_accuracy: 0.9833\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 164ms/step - loss: 0.0540 - accuracy: 0.9833 - val_loss: 0.0601 - val_accuracy: 0.9802\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0640 - accuracy: 0.9802\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0601 - accuracy: 0.9802\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 163ms/step - loss: 2.3123 - accuracy: 0.1160 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 161ms/step - loss: 2.3016 - accuracy: 0.1120 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 162ms/step - loss: 2.3017 - accuracy: 0.1121 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 161ms/step - loss: 2.3017 - accuracy: 0.1119 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 161ms/step - loss: 2.3017 - accuracy: 0.1123 - val_loss: 2.3020 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 2.3017 - accuracy: 0.1124\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.3020 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 21s 168ms/step - loss: 0.6329 - accuracy: 0.8157 - val_loss: 0.2148 - val_accuracy: 0.9356\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 166ms/step - loss: 0.1696 - accuracy: 0.9482 - val_loss: 0.1187 - val_accuracy: 0.9622\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 166ms/step - loss: 0.1064 - accuracy: 0.9683 - val_loss: 0.0825 - val_accuracy: 0.9729\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 166ms/step - loss: 0.0786 - accuracy: 0.9757 - val_loss: 0.1050 - val_accuracy: 0.9666\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 20s 166ms/step - loss: 0.0640 - accuracy: 0.9805 - val_loss: 0.0843 - val_accuracy: 0.9731\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0830 - accuracy: 0.9734\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0843 - accuracy: 0.9731\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 21s 168ms/step - loss: 0.3843 - accuracy: 0.8780 - val_loss: 0.0932 - val_accuracy: 0.9713\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 171ms/step - loss: 0.0870 - accuracy: 0.9727 - val_loss: 0.0653 - val_accuracy: 0.9783\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 170ms/step - loss: 0.0546 - accuracy: 0.9829 - val_loss: 0.1712 - val_accuracy: 0.9463\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 171ms/step - loss: 0.0422 - accuracy: 0.9865 - val_loss: 0.0500 - val_accuracy: 0.9827\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 20s 173ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 0.0427 - val_accuracy: 0.9877\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0282 - accuracy: 0.9909\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.0427 - accuracy: 0.9877\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 21s 169ms/step - loss: 0.4087 - accuracy: 0.8763 - val_loss: 0.3220 - val_accuracy: 0.8868\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 171ms/step - loss: 0.0885 - accuracy: 0.9740 - val_loss: 0.1448 - val_accuracy: 0.9546\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 171ms/step - loss: 0.0610 - accuracy: 0.9824 - val_loss: 0.1020 - val_accuracy: 0.9723\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 170ms/step - loss: 0.0459 - accuracy: 0.9869 - val_loss: 0.2432 - val_accuracy: 0.9344\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 20s 170ms/step - loss: 0.0390 - accuracy: 0.9883 - val_loss: 0.0410 - val_accuracy: 0.9878\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0214 - accuracy: 0.9930\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0410 - accuracy: 0.9878\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 167ms/step - loss: 2.5412 - accuracy: 0.1085 - val_loss: 2.3045 - val_accuracy: 0.1010\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 2.4498 - accuracy: 0.1105 - val_loss: 2.2273 - val_accuracy: 0.2888\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 0.6701 - accuracy: 0.7822 - val_loss: 0.2392 - val_accuracy: 0.9323\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 0.2046 - accuracy: 0.9423 - val_loss: 0.1533 - val_accuracy: 0.9580\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 20s 172ms/step - loss: 0.1456 - accuracy: 0.9603 - val_loss: 0.1887 - val_accuracy: 0.9510\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.1779 - accuracy: 0.9512\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.1887 - accuracy: 0.9510\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 163ms/step - loss: 121.0163 - accuracy: 0.1066 - val_loss: 2.3172 - val_accuracy: 0.1010\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 163ms/step - loss: 2.3055 - accuracy: 0.1059 - val_loss: 2.3118 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 163ms/step - loss: 2.3054 - accuracy: 0.1056 - val_loss: 2.3099 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 163ms/step - loss: 2.3054 - accuracy: 0.1058 - val_loss: 2.3092 - val_accuracy: 0.0892\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 163ms/step - loss: 2.3051 - accuracy: 0.1047 - val_loss: 2.3106 - val_accuracy: 0.0980\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 2.3102 - accuracy: 0.0987\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 2.3106 - accuracy: 0.0980\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 161ms/step - loss: 14366.8174 - accuracy: 0.1202 - val_loss: 2.3363 - val_accuracy: 0.1010\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 162ms/step - loss: 2.3956 - accuracy: 0.1022 - val_loss: 2.4101 - val_accuracy: 0.1028\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 162ms/step - loss: 2.3183 - accuracy: 0.1047 - val_loss: 2.3248 - val_accuracy: 0.0982\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 162ms/step - loss: 2.3180 - accuracy: 0.1029 - val_loss: 2.3394 - val_accuracy: 0.0980\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 162ms/step - loss: 2.3194 - accuracy: 0.1037 - val_loss: 2.4384 - val_accuracy: 0.0982\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 2.4392 - accuracy: 0.0974\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 2.4384 - accuracy: 0.0982\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 164ms/step - loss: 2.3043 - accuracy: 0.0936 - val_loss: 2.3034 - val_accuracy: 0.0967\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.3025 - accuracy: 0.0940 - val_loss: 2.3015 - val_accuracy: 0.0967\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.3007 - accuracy: 0.0947 - val_loss: 2.2997 - val_accuracy: 0.0976\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2988 - accuracy: 0.0952 - val_loss: 2.2978 - val_accuracy: 0.0990\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2969 - accuracy: 0.0962 - val_loss: 2.2958 - val_accuracy: 0.0990\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 2.2959 - accuracy: 0.0966\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 2.2958 - accuracy: 0.0990\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 164ms/step - loss: 2.3025 - accuracy: 0.0940 - val_loss: 2.2996 - val_accuracy: 0.0968\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 164ms/step - loss: 2.2969 - accuracy: 0.0963 - val_loss: 2.2938 - val_accuracy: 0.1012\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2911 - accuracy: 0.1015 - val_loss: 2.2877 - val_accuracy: 0.1077\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2849 - accuracy: 0.1134 - val_loss: 2.2811 - val_accuracy: 0.1244\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.2781 - accuracy: 0.1386 - val_loss: 2.2739 - val_accuracy: 0.1589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:92: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:97: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:102: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:107: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 15s 8ms/step - loss: 2.2744 - accuracy: 0.1574\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 2.2739 - accuracy: 0.1589\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 163ms/step - loss: 2.2968 - accuracy: 0.0968 - val_loss: 2.2876 - val_accuracy: 0.1074\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 163ms/step - loss: 2.2777 - accuracy: 0.1412 - val_loss: 2.2653 - val_accuracy: 0.2055\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 163ms/step - loss: 2.2500 - accuracy: 0.2794 - val_loss: 2.2288 - val_accuracy: 0.3626\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 163ms/step - loss: 2.1982 - accuracy: 0.4184 - val_loss: 2.1522 - val_accuracy: 0.4930\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 164ms/step - loss: 2.0774 - accuracy: 0.5446 - val_loss: 1.9602 - val_accuracy: 0.6032\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 1.9667 - accuracy: 0.5948\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 1.9602 - accuracy: 0.6032\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 165ms/step - loss: 2.2753 - accuracy: 0.1786 - val_loss: 2.2294 - val_accuracy: 0.3697\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 2.0234 - accuracy: 0.5426 - val_loss: 1.4927 - val_accuracy: 0.6998\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 0.8750 - accuracy: 0.7873 - val_loss: 0.5306 - val_accuracy: 0.8577\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 0.4658 - accuracy: 0.8682 - val_loss: 0.3924 - val_accuracy: 0.8901\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 19s 165ms/step - loss: 0.3659 - accuracy: 0.8965 - val_loss: 0.3445 - val_accuracy: 0.8992\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3597 - accuracy: 0.8937\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.3445 - accuracy: 0.8992\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 20s 166ms/step - loss: 1.8024 - accuracy: 0.4758 - val_loss: 0.7776 - val_accuracy: 0.7384\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 20s 167ms/step - loss: 0.4857 - accuracy: 0.8510 - val_loss: 0.3351 - val_accuracy: 0.8966\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 20s 169ms/step - loss: 0.2751 - accuracy: 0.9190 - val_loss: 0.2468 - val_accuracy: 0.9249\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.2106 - accuracy: 0.9376 - val_loss: 0.1866 - val_accuracy: 0.9425\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.1775 - accuracy: 0.9472 - val_loss: 0.1727 - val_accuracy: 0.9463\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1785 - accuracy: 0.9449\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1727 - accuracy: 0.9463\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 181ms/step - loss: 1.0553 - accuracy: 0.6748 - val_loss: 0.4013 - val_accuracy: 0.8675\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 178ms/step - loss: 0.2222 - accuracy: 0.9331 - val_loss: 0.1639 - val_accuracy: 0.9508\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 0.1472 - accuracy: 0.9555 - val_loss: 0.1769 - val_accuracy: 0.9463\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.1184 - accuracy: 0.9646 - val_loss: 0.1011 - val_accuracy: 0.9662\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 0.1018 - accuracy: 0.9696 - val_loss: 0.0960 - val_accuracy: 0.9689\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1053 - accuracy: 0.9675\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0960 - accuracy: 0.9689\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 182ms/step - loss: 1.0066 - accuracy: 0.7552 - val_loss: 0.3037 - val_accuracy: 0.9176\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.2396 - accuracy: 0.9311 - val_loss: 0.1820 - val_accuracy: 0.9475\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 181ms/step - loss: 0.1625 - accuracy: 0.9526 - val_loss: 0.1288 - val_accuracy: 0.9617\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 0.1265 - accuracy: 0.9625 - val_loss: 0.1037 - val_accuracy: 0.9681\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 0.1080 - accuracy: 0.9679 - val_loss: 0.0941 - val_accuracy: 0.9721\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.1000 - accuracy: 0.9708\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0941 - accuracy: 0.9721\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 181ms/step - loss: 0.5333 - accuracy: 0.8505 - val_loss: 0.1819 - val_accuracy: 0.9449\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 0.1377 - accuracy: 0.9590 - val_loss: 0.1047 - val_accuracy: 0.9684\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.0972 - accuracy: 0.9708 - val_loss: 0.0806 - val_accuracy: 0.9740\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.0789 - accuracy: 0.9764 - val_loss: 0.0580 - val_accuracy: 0.9814\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.0660 - accuracy: 0.9801 - val_loss: 0.0588 - val_accuracy: 0.9796\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0592 - accuracy: 0.9825\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0588 - accuracy: 0.9796\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 180ms/step - loss: 0.3133 - accuracy: 0.9027 - val_loss: 0.0946 - val_accuracy: 0.9709\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 0.0829 - accuracy: 0.9750 - val_loss: 0.0599 - val_accuracy: 0.9810\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 0.0613 - accuracy: 0.9818 - val_loss: 0.0543 - val_accuracy: 0.9830\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.0500 - accuracy: 0.9841 - val_loss: 0.0475 - val_accuracy: 0.9842\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 0.0408 - accuracy: 0.9876 - val_loss: 0.0365 - val_accuracy: 0.9881\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0321 - accuracy: 0.9904\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0365 - accuracy: 0.9881\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 178ms/step - loss: 0.2683 - accuracy: 0.9099 - val_loss: 0.0593 - val_accuracy: 0.9809\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 178ms/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 0.0562 - val_accuracy: 0.9817\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 181ms/step - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.0412 - val_accuracy: 0.9866\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 182ms/step - loss: 0.0363 - accuracy: 0.9882 - val_loss: 0.0490 - val_accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 182ms/step - loss: 0.0331 - accuracy: 0.9893 - val_loss: 0.0545 - val_accuracy: 0.9830\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0394 - accuracy: 0.9873\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0545 - accuracy: 0.9830\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 179ms/step - loss: 1.7217 - accuracy: 0.5559 - val_loss: 0.3132 - val_accuracy: 0.9029\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 177ms/step - loss: 0.2323 - accuracy: 0.9272 - val_loss: 0.1645 - val_accuracy: 0.9497\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 178ms/step - loss: 0.1723 - accuracy: 0.9452 - val_loss: 0.1506 - val_accuracy: 0.9523\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.1415 - accuracy: 0.9560 - val_loss: 0.2120 - val_accuracy: 0.9352\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 0.1300 - accuracy: 0.9594 - val_loss: 0.1248 - val_accuracy: 0.9642\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0944 - accuracy: 0.9690\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1248 - accuracy: 0.9642\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 179ms/step - loss: 40.6067 - accuracy: 0.1060 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 177ms/step - loss: 2.3021 - accuracy: 0.1096 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 2.3023 - accuracy: 0.1089 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 22s 184ms/step - loss: 2.3019 - accuracy: 0.1092 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 22s 191ms/step - loss: 2.3024 - accuracy: 0.1093 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 2.3020 - accuracy: 0.1124\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.3017 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 23s 187ms/step - loss: 0.6970 - accuracy: 0.8100 - val_loss: 0.2507 - val_accuracy: 0.9263\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 22s 185ms/step - loss: 0.1470 - accuracy: 0.9564 - val_loss: 0.1597 - val_accuracy: 0.9520\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 22s 184ms/step - loss: 0.0985 - accuracy: 0.9701 - val_loss: 0.0946 - val_accuracy: 0.9699\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 22s 184ms/step - loss: 0.0785 - accuracy: 0.9758 - val_loss: 0.0731 - val_accuracy: 0.9762\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 22s 185ms/step - loss: 0.0667 - accuracy: 0.9795 - val_loss: 0.1665 - val_accuracy: 0.9439\n",
            "1875/1875 [==============================] - 24s 12ms/step - loss: 0.1649 - accuracy: 0.9439\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.1665 - accuracy: 0.9439\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 23s 181ms/step - loss: 0.4227 - accuracy: 0.8692 - val_loss: 0.1179 - val_accuracy: 0.9646\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.0833 - accuracy: 0.9742 - val_loss: 0.0786 - val_accuracy: 0.9752\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 22s 182ms/step - loss: 0.0558 - accuracy: 0.9818 - val_loss: 0.0489 - val_accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 22s 184ms/step - loss: 0.0417 - accuracy: 0.9873 - val_loss: 0.2175 - val_accuracy: 0.9306\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 0.1372 - accuracy: 0.9650 - val_loss: 0.0514 - val_accuracy: 0.9828\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0435 - accuracy: 0.9865\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0514 - accuracy: 0.9828\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 23s 182ms/step - loss: 0.3442 - accuracy: 0.8887 - val_loss: 0.2665 - val_accuracy: 0.9127\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 182ms/step - loss: 0.0613 - accuracy: 0.9811 - val_loss: 0.0654 - val_accuracy: 0.9773\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 181ms/step - loss: 0.1052 - accuracy: 0.9682 - val_loss: 0.0638 - val_accuracy: 0.9793\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 181ms/step - loss: 0.0409 - accuracy: 0.9872 - val_loss: 0.0421 - val_accuracy: 0.9856\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 181ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.2196 - val_accuracy: 0.9374\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1835 - accuracy: 0.9442\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2196 - accuracy: 0.9374\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 23s 182ms/step - loss: 0.6834 - accuracy: 0.7692 - val_loss: 0.1515 - val_accuracy: 0.9543\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 182ms/step - loss: 0.1097 - accuracy: 0.9664 - val_loss: 0.0990 - val_accuracy: 0.9703\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 182ms/step - loss: 0.0826 - accuracy: 0.9749 - val_loss: 0.3446 - val_accuracy: 0.8985\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 2.4266 - accuracy: 0.1239 - val_loss: 2.3016 - val_accuracy: 0.1028\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 2.3019 - accuracy: 0.1111 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3015 - accuracy: 0.1124\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.3014 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 181ms/step - loss: 2.6967 - accuracy: 0.1079 - val_loss: 2.3032 - val_accuracy: 0.0958\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 178ms/step - loss: 2.3029 - accuracy: 0.1089 - val_loss: 2.3048 - val_accuracy: 0.1010\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 178ms/step - loss: 2.3033 - accuracy: 0.1077 - val_loss: 2.3047 - val_accuracy: 0.0958\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 178ms/step - loss: 2.3033 - accuracy: 0.1084 - val_loss: 2.3034 - val_accuracy: 0.1032\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 177ms/step - loss: 2.3031 - accuracy: 0.1090 - val_loss: 2.3092 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3104 - accuracy: 0.1124\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.3092 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 178ms/step - loss: 48.1818 - accuracy: 0.1095 - val_loss: 2.3073 - val_accuracy: 0.1010\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 175ms/step - loss: 2.3050 - accuracy: 0.1054 - val_loss: 2.3306 - val_accuracy: 0.0974\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 176ms/step - loss: 2.3060 - accuracy: 0.1046 - val_loss: 2.3164 - val_accuracy: 0.1028\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 176ms/step - loss: 2.3065 - accuracy: 0.1054 - val_loss: 2.3310 - val_accuracy: 0.0974\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 175ms/step - loss: 2.3069 - accuracy: 0.1058 - val_loss: 2.3067 - val_accuracy: 0.1032\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3075 - accuracy: 0.0993\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.3067 - accuracy: 0.1032\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 23s 186ms/step - loss: 2.3026 - accuracy: 0.1119 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 2.3025 - accuracy: 0.1124 - val_loss: 2.3024 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 2.3024 - accuracy: 0.1124 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 2.3023 - accuracy: 0.1124 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 178ms/step - loss: 2.3023 - accuracy: 0.1124 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3022 - accuracy: 0.1124\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.3022 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 181ms/step - loss: 2.3025 - accuracy: 0.1119 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 2.3022 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 2.3020 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 179ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 178ms/step - loss: 2.3018 - accuracy: 0.1124 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3017 - accuracy: 0.1124\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.3017 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 183ms/step - loss: 2.3022 - accuracy: 0.1122 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 2.3017 - accuracy: 0.1124 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 182ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 22s 182ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3012 - accuracy: 0.1124\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.3011 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 183ms/step - loss: 2.3018 - accuracy: 0.1117 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 181ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 181ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3012 - accuracy: 0.1124\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.3010 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 184ms/step - loss: 2.3016 - accuracy: 0.1118 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 22s 183ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 22s 186ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 22s 183ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 22s 183ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3012 - accuracy: 0.1124\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 2.3010 - accuracy: 0.1135\n",
            "Epoch 1/5\n",
            "118/118 [==============================] - 22s 184ms/step - loss: 2.3017 - accuracy: 0.1116 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
            "Epoch 2/5\n",
            "118/118 [==============================] - 21s 181ms/step - loss: 2.3017 - accuracy: 0.1123 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
            "Epoch 3/5\n",
            "118/118 [==============================] - 21s 180ms/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
            "Epoch 4/5\n",
            "118/118 [==============================] - 21s 182ms/step - loss: 2.3015 - accuracy: 0.1120 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
            "Epoch 5/5\n",
            "118/118 [==============================] - 22s 182ms/step - loss: 2.3015 - accuracy: 0.1123 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 2.3016 - accuracy: 0.1124\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 2.3017 - accuracy: 0.1135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          validation_split = .1,\n",
        "          verbose = 1)\n",
        "\"\"\"\n",
        "\n",
        "print(dfhist)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxj-csi5pTfc",
        "outputId": "1b3cad92-7d33-4ec9-e87d-7bc19166c7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   (Adam, 0.001, Training Loss)  (Adam, 0.001, Training Accuracy)  \\\n",
            "0                      0.324658                            0.9063   \n",
            "\n",
            "   (Adam, 0.001, Validation Loss)  (Adam, 0.001, Validation Accuracy)  \n",
            "0                        0.096332                              0.9695  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.history.history)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df2 = pd.DataFrame()\n",
        "lst = model.history.history[\"loss\"]\n",
        "lst.reverse()\n",
        "df[(\"optimizer\",\"rate\",\"loss\")] = lst\n",
        "\n",
        "df2[(\"optimizer\",\"rate\")] = [1,2,3,4]\n",
        "\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "Cm0DR1e1pZ1u",
        "outputId": "0fdd3e29-6f9d-4da8-b72f-c282899675bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-35878d3fe189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optimizer\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'loss'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSmlIJqGZBoC"
      },
      "source": [
        "## Plot Prediction and Network Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jdEKBFK5uzE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "outputId": "e6f56b02-fd34-4351-ea8c-98e0fa90e405"
      },
      "source": [
        "n_images = 3\n",
        "outs = list(model.predict(x_test[:n_images,:,:,:]))\n",
        "preds = list(np.argmax(model.predict(x_test[:n_images,:,:,:]), axis=-1))\n",
        "\n",
        "# Display\n",
        "for i in range(n_images):\n",
        "    plt.imshow(x_test[i,:,:,0], cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"Network prediction:\", preds[i])\n",
        "    print(\"Network Output:\", outs[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAM3ElEQVR4nO3dXahc9bnH8d/vpCmI6UXiS9ik0bTBC8tBEo1BSCxbQktOvIjFIM1FyYHi7kWUFkuo2It4WaQv1JvALkrTkmMJpGoQscmJxVDU4o5Es2NIjCGaxLxYIjQRJMY+vdjLso0za8ZZa2ZN8nw/sJmZ9cya9bDMz7VmvczfESEAV77/aroBAINB2IEkCDuQBGEHkiDsQBJfGeTCbHPoH+iziHCr6ZW27LZX2j5o+7Dth6t8FoD+cq/n2W3PkHRI0nckHZf0mqS1EfFWyTxs2YE+68eWfamkwxFxJCIuSPqTpNUVPg9AH1UJ+zxJx6a9Pl5M+xzbY7YnbE9UWBaAivp+gC4ixiWNS+zGA02qsmU/IWn+tNdfL6YBGEJVwv6apJtsf8P2VyV9X9L2etoCULeed+Mj4qLtByT9RdIMSU9GxP7aOgNQq55PvfW0ML6zA33Xl4tqAFw+CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ9Dw+uyTZPirpnKRPJV2MiCV1NAWgfpXCXrgrIv5Rw+cA6CN244EkqoY9JO2wvcf2WKs32B6zPWF7ouKyAFTgiOh9ZnteRJywfb2knZIejIjdJe/vfWEAuhIRbjW90pY9Ik4Uj2ckPS1paZXPA9A/PYfd9tW2v/bZc0nflTRZV2MA6lXlaPxcSU/b/uxz/i8iXqilKwC1q/Sd/UsvjO/sQN/15Ts7gMsHYQeSIOxAEoQdSIKwA0nUcSNMCmvWrGlbu//++0vnff/990vrH3/8cWl9y5YtpfVTp061rR0+fLh0XuTBlh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuCuty4dOXKkbW3BggWDa6SFc+fOta3t379/gJ0Ml+PHj7etPfbYY6XzTkxcvr+ixl1vQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AE97N3qeye9VtuuaV03gMHDpTWb7755tL6rbfeWlofHR1tW7vjjjtK5z127Fhpff78+aX1Ki5evFha/+CDD0rrIyMjPS/7vffeK61fzufZ22HLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcD/7FWD27Nlta4sWLSqdd8+ePaX122+/vaeeutHp9/IPHTpUWu90/cKcOXPa1tavX18676ZNm0rrw6zn+9ltP2n7jO3JadPm2N5p++3isf2/NgBDoZvd+N9LWnnJtIcl7YqImyTtKl4DGGIdwx4RuyWdvWTyakmbi+ebJd1Tc18AatbrtfFzI+Jk8fyUpLnt3mh7TNJYj8sBUJPKN8JERJQdeIuIcUnjEgfogCb1eurttO0RSSoez9TXEoB+6DXs2yWtK56vk/RsPe0A6JeO59ltPyVpVNK1kk5L2ijpGUlbJd0g6V1J90XEpQfxWn0Wu/Ho2r333lta37p1a2l9cnKybe2uu+4qnffs2Y7/nIdWu/PsHb+zR8TaNqUVlToCMFBcLgskQdiBJAg7kARhB5Ig7EAS3OKKxlx//fWl9X379lWaf82aNW1r27ZtK533csaQzUByhB1IgrADSRB2IAnCDiRB2IEkCDuQBEM2ozGdfs75uuuuK61/+OGHpfWDBw9+6Z6uZGzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ7mdHXy1btqxt7cUXXyydd+bMmaX10dHR0vru3btL61cq7mcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSS4nx19tWrVqra1TufRd+3aVVp/5ZVXeuopq45bdttP2j5je3LatEdtn7C9t/hr/18UwFDoZjf+95JWtpj+m4hYVPw9X29bAOrWMewRsVvS2QH0AqCPqhyge8D2m8Vu/ux2b7I9ZnvC9kSFZQGoqNewb5K0UNIiSScl/ardGyNiPCKWRMSSHpcFoAY9hT0iTkfEpxHxL0m/k7S03rYA1K2nsNsemfbye5Im270XwHDoeJ7d9lOSRiVda/u4pI2SRm0vkhSSjkr6UR97xBC76qqrSusrV7Y6kTPlwoULpfNu3LixtP7JJ5+U1vF5HcMeEWtbTH6iD70A6CMulwWSIOxAEoQdSIKwA0kQdiAJbnFFJRs2bCitL168uG3thRdeKJ335Zdf7qkntMaWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYMhmlLr77rtL688880xp/aOPPmpbK7v9VZJeffXV0jpaY8hmIDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC+9mTu+aaa0rrjz/+eGl9xowZpfXnn28/5ifn0QeLLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMH97Fe4TufBO53rvu2220rr77zzTmm97J71TvOiNz3fz257vu2/2n7L9n7bPy6mz7G90/bbxePsupsGUJ9uduMvSvppRHxL0h2S1tv+lqSHJe2KiJsk7SpeAxhSHcMeEScj4vXi+TlJByTNk7Ra0ubibZsl3dOvJgFU96Wujbe9QNJiSX+XNDciThalU5LmtplnTNJY7y0CqEPXR+Ntz5K0TdJPIuKf02sxdZSv5cG3iBiPiCURsaRSpwAq6SrstmdqKuhbIuLPxeTTtkeK+oikM/1pEUAdOu7G27akJyQdiIhfTyttl7RO0i+Kx2f70iEqWbhwYWm906m1Th566KHSOqfXhkc339mXSfqBpH229xbTHtFUyLfa/qGkdyXd158WAdShY9gj4m+SWp6kl7Si3nYA9AuXywJJEHYgCcIOJEHYgSQIO5AEPyV9Bbjxxhvb1nbs2FHpszds2FBaf+655yp9PgaHLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59ivA2Fj7X/264YYbKn32Sy+9VFof5E+Roxq27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOfZLwPLly8vrT/44IMD6gSXM7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEN+Ozz5f0B0lzJYWk8Yj4re1HJd0v6YPirY9ExPP9ajSzO++8s7Q+a9asnj+70/jp58+f7/mzMVy6uajmoqSfRsTrtr8maY/tnUXtNxHxy/61B6Au3YzPflLSyeL5OdsHJM3rd2MA6vWlvrPbXiBpsaS/F5MesP2m7Sdtz24zz5jtCdsTlToFUEnXYbc9S9I2ST+JiH9K2iRpoaRFmtry/6rVfBExHhFLImJJDf0C6FFXYbc9U1NB3xIRf5akiDgdEZ9GxL8k/U7S0v61CaCqjmG3bUlPSDoQEb+eNn1k2tu+J2my/vYA1KWbo/HLJP1A0j7be4tpj0haa3uRpk7HHZX0o750iEreeOON0vqKFStK62fPnq2zHTSom6Pxf5PkFiXOqQOXEa6gA5Ig7EAShB1IgrADSRB2IAnCDiThQQ65a5vxfYE+i4hWp8rZsgNZEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoMesvkfkt6d9vraYtowGtbehrUvid56VWdvN7YrDPSimi8s3J4Y1t+mG9behrUvid56Naje2I0HkiDsQBJNh3284eWXGdbehrUvid56NZDeGv3ODmBwmt6yAxgQwg4k0UjYba+0fdD2YdsPN9FDO7aP2t5ne2/T49MVY+idsT05bdoc2zttv108thxjr6HeHrV9olh3e22vaqi3+bb/avst2/tt/7iY3ui6K+lrIOtt4N/Zbc+QdEjSdyQdl/SapLUR8dZAG2nD9lFJSyKi8QswbH9b0nlJf4iI/y6mPSbpbET8ovgf5eyI+NmQ9PaopPNND+NdjFY0Mn2YcUn3SPpfNbjuSvq6TwNYb01s2ZdKOhwRRyLigqQ/SVrdQB9DLyJ2S7p0SJbVkjYXzzdr6h/LwLXpbShExMmIeL14fk7SZ8OMN7ruSvoaiCbCPk/SsWmvj2u4xnsPSTts77E91nQzLcyNiJPF81OS5jbZTAsdh/EepEuGGR+addfL8OdVcYDui5ZHxK2S/kfS+mJ3dSjF1HewYTp32tUw3oPSYpjx/2hy3fU6/HlVTYT9hKT5015/vZg2FCLiRPF4RtLTGr6hqE9/NoJu8Xim4X7+Y5iG8W41zLiGYN01Ofx5E2F/TdJNtr9h+6uSvi9pewN9fIHtq4sDJ7J9taTvaviGot4uaV3xfJ2kZxvs5XOGZRjvdsOMq+F11/jw5xEx8D9JqzR1RP4dST9vooc2fX1T0hvF3/6me5P0lKZ26z7R1LGNH0q6RtIuSW9L+n9Jc4aotz9K2ifpTU0Fa6Sh3pZrahf9TUl7i79VTa+7kr4Gst64XBZIggN0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEvwEvYRv57rmVLgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Network prediction: 7\n",
            "Network Output: [6.8719248e-07 2.1010560e-07 1.6415802e-04 6.8870082e-05 3.7615578e-08\n",
            " 2.2365189e-06 2.7995849e-11 9.9974877e-01 6.0050970e-06 9.0470494e-06]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Network prediction: 2\n",
            "Network Output: [7.3275354e-05 4.7033641e-04 9.9931335e-01 1.3596324e-04 9.0491387e-10\n",
            " 6.7844866e-07 1.5558460e-07 3.2796588e-09 6.2710501e-06 9.0346175e-10]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMEElEQVR4nO3dXYhc5R3H8d+vabwwepFUE4OKsRJRUUzKIoKhWnzBBiHmRoxQEiqsFwYi9KJiLxRKQaTaCy+EFcU0WF+IBqPWaBrEtDeaVVNNfIlWIiasWSWCb4g1+fdiT8oad85s5pwzZ9z/9wPLzDzPnDl/DvnlOXNe5nFECMDM95O2CwDQH4QdSIKwA0kQdiAJwg4k8dN+rsw2h/6BhkWEp2qvNLLbvtr2u7bft31rlc8C0Cz3ep7d9ixJeyRdKWmfpB2SVkXEWyXLMLIDDWtiZL9I0vsR8UFEfCvpUUkrKnwegAZVCfupkj6a9Hpf0fY9todtj9oerbAuABU1foAuIkYkjUjsxgNtqjKy75d0+qTXpxVtAAZQlbDvkLTY9pm2j5N0vaTN9ZQFoG4978ZHxHe210p6XtIsSQ9GxO7aKgNQq55PvfW0Mr6zA41r5KIaAD8ehB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dcpm5HP2Wef3bHvnXfeKV123bp1pf333ntvTzVlxcgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwnh2NWrp0ace+w4cPly67b9++ustJrVLYbe+V9IWkQ5K+i4ihOooCUL86RvZfRcSnNXwOgAbxnR1IomrYQ9ILtl+1PTzVG2wP2x61PVpxXQAqqLobvywi9tueL2mr7XciYvvkN0TEiKQRSbIdFdcHoEeVRvaI2F88jkvaJOmiOooCUL+ew257ju0TjzyXdJWkXXUVBqBeVXbjF0jaZPvI5/wtIrbUUhVmjCVLlnTs++qrr0qX3bRpU93lpNZz2CPiA0kX1lgLgAZx6g1IgrADSRB2IAnCDiRB2IEkuMUVlZx//vml/WvXru3Yt2HDhrrLQQlGdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgvPsqOScc84p7Z8zZ07Hvscee6zuclCCkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHknBE/yZpYUaYmeeVV14p7T/55JM79nW7F77bT01jahHhqdoZ2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCe5nR6lFixaV9g8NDZX279mzp2Mf59H7q+vIbvtB2+O2d01qm2d7q+33ise5zZYJoKrp7MY/JOnqo9pulbQtIhZL2la8BjDAuoY9IrZLOnhU8wpJ64vn6yVdW3NdAGrW63f2BRExVjz/WNKCTm+0PSxpuMf1AKhJ5QN0ERFlN7hExIikEYkbYYA29Xrq7YDthZJUPI7XVxKAJvQa9s2SVhfPV0t6qp5yADSl62687UckXSbpJNv7JN0u6U5Jj9u+UdKHkq5rski059JLL620/CeffFJTJaiqa9gjYlWHrstrrgVAg7hcFkiCsANJEHYgCcIOJEHYgSS4xRWlLrjggkrL33XXXTVVgqoY2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCaZsTu7iiy8u7X/22WdL+/fu3Vvaf8kll3Ts++abb0qXRW+YshlIjrADSRB2IAnCDiRB2IEkCDuQBGEHkuB+9uSuuOKK0v558+aV9m/ZsqW0n3Ppg4ORHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dx7chdeeGFpf7ffO9i4cWOd5aBBXUd22w/aHre9a1LbHbb3295Z/C1vtkwAVU1nN/4hSVdP0f6XiFhS/P293rIA1K1r2CNiu6SDfagFQIOqHKBba/uNYjd/bqc32R62PWp7tMK6AFTUa9jvk3SWpCWSxiTd3emNETESEUMRMdTjugDUoKewR8SBiDgUEYcl3S/ponrLAlC3nsJue+Gklysl7er0XgCDoevvxtt+RNJlkk6SdEDS7cXrJZJC0l5JN0XEWNeV8bvxfXfKKaeU9u/cubO0/7PPPivtP/fcc4+5JjSr0+/Gd72oJiJWTdH8QOWKAPQVl8sCSRB2IAnCDiRB2IEkCDuQBLe4znBr1qwp7Z8/f35p/3PPPVdjNWgTIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59hnujDPOqLR8t1tc8ePByA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXCefYa75pprKi3/9NNP11QJ2sbIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ59Bli2bFnHvm5TNiOPriO77dNtv2j7Ldu7ba8r2ufZ3mr7veJxbvPlAujVdHbjv5P0u4g4T9LFkm62fZ6kWyVti4jFkrYVrwEMqK5hj4ixiHiteP6FpLclnSpphaT1xdvWS7q2qSIBVHdM39ltL5K0VNLLkhZExFjR9bGkBR2WGZY03HuJAOow7aPxtk+Q9ISkWyLi88l9ERGSYqrlImIkIoYiYqhSpQAqmVbYbc/WRNAfjogni+YDthcW/QsljTdTIoA6dN2Nt21JD0h6OyLumdS1WdJqSXcWj081UiG6WrlyZce+WbNmlS77+uuvl/Zv3769p5oweKbznf0SSb+R9KbtnUXbbZoI+eO2b5T0oaTrmikRQB26hj0i/iXJHbovr7ccAE3hclkgCcIOJEHYgSQIO5AEYQeS4BbXH4Hjjz++tH/58uU9f/bGjRtL+w8dOtTzZ2OwMLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKe+JGZPq3M7t/KZpDZs2eX9r/00ksd+8bHy39T5IYbbijt//rrr0v7MXgiYsq7VBnZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJzrMDMwzn2YHkCDuQBGEHkiDsQBKEHUiCsANJEHYgia5ht3267Rdtv2V7t+11Rfsdtvfb3ln89f7j5QAa1/WiGtsLJS2MiNdsnyjpVUnXamI+9i8j4s/TXhkX1QCN63RRzXTmZx+TNFY8/8L225JOrbc8AE07pu/sthdJWirp5aJpre03bD9oe26HZYZtj9oerVQpgEqmfW287RMkvSTpTxHxpO0Fkj6VFJL+qIld/d92+Qx244GGddqNn1bYbc+W9Iyk5yPinin6F0l6JiLO7/I5hB1oWM83wti2pAckvT056MWBuyNWStpVtUgAzZnO0fhlkv4p6U1Jh4vm2yStkrREE7vxeyXdVBzMK/ssRnagYZV24+tC2IHmcT87kBxhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgia4/OFmzTyV9OOn1SUXbIBrU2ga1LonaelVnbWd06ujr/ew/WLk9GhFDrRVQYlBrG9S6JGrrVb9qYzceSIKwA0m0HfaRltdfZlBrG9S6JGrrVV9qa/U7O4D+aXtkB9AnhB1IopWw277a9ru237d9axs1dGJ7r+03i2moW52frphDb9z2rklt82xvtf1e8TjlHHst1TYQ03iXTDPe6rZre/rzvn9ntz1L0h5JV0raJ2mHpFUR8VZfC+nA9l5JQxHR+gUYtn8p6UtJfz0ytZbtuyQdjIg7i/8o50bE7wektjt0jNN4N1Rbp2nG16jFbVfn9Oe9aGNkv0jS+xHxQUR8K+lRSStaqGPgRcR2SQePal4haX3xfL0m/rH0XYfaBkJEjEXEa8XzLyQdmWa81W1XUldftBH2UyV9NOn1Pg3WfO8h6QXbr9oebruYKSyYNM3Wx5IWtFnMFLpO491PR00zPjDbrpfpz6viAN0PLYuIX0j6taSbi93VgRQT38EG6dzpfZLO0sQcgGOS7m6zmGKa8Sck3RIRn0/ua3PbTVFXX7ZbG2HfL+n0Sa9PK9oGQkTsLx7HJW3SxNeOQXLgyAy6xeN4y/X8X0QciIhDEXFY0v1qcdsV04w/IenhiHiyaG59201VV7+2Wxth3yFpse0zbR8n6XpJm1uo4wdszykOnMj2HElXafCmot4saXXxfLWkp1qs5XsGZRrvTtOMq+Vt1/r05xHR9z9JyzVxRP4/kv7QRg0d6vq5pH8Xf7vbrk3SI5rYrfuvJo5t3CjpZ5K2SXpP0j8kzRug2jZoYmrvNzQRrIUt1bZME7vob0jaWfwtb3vbldTVl+3G5bJAEhygA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/gciQMnFg+KOfAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Network prediction: 1\n",
            "Network Output: [4.4673790e-05 9.9867356e-01 1.5157984e-04 2.4063715e-05 4.8875512e-04\n",
            " 1.0814914e-05 1.9844124e-04 9.5495692e-05 2.9402963e-04 1.8622628e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7RGUcw-NCMe"
      },
      "source": [
        "# Food for thought\n",
        "\n",
        "- Artificial Intelligence = Machine Learning = Neural Networks ???\n",
        "- Moravecs Paradox: It is comparatively easy to make computers exhibit adult level performance on intelligence tests, playing checkers or calculating pi to a billion digits, but difficult or impossible to give them the skills of a one-year-old when it comes to perception and mobility The mental abilities of a child that we take for granted  recognizing a face, lifting a pencil, or walking across a room  in fact solve some of the hardest engineering problems ever conceived Encoded in the large, highly evolved sensory and motor portions of the human brain is a billion years of experience about the nature of the world and how to survive in it. \n",
        "- AI winters: Over-promising and Under-delivering \n",
        "- AI Revolution: Has it happened yet? ([Michael I. Jordan](https://hdsr.mitpress.mit.edu/pub/wot7mkc1/release/9))"
      ]
    }
  ]
}